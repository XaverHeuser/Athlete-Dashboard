{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "_GCP_PROJECT_ID = os.getenv('GCP_PROJECT_ID')\n",
    "_BQ_DATASET_MARTS = os.getenv('BIGQUERY_DATASET_MARTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de570c8f",
   "metadata": {},
   "source": [
    "# BigQuery Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    creds = service_account.Credentials.from_service_account_info(\n",
    "        st.secrets['gcp_service_account']\n",
    "    )\n",
    "    client = bigquery.Client(credentials=creds, project=creds.project_id)\n",
    "except Exception:\n",
    "    # Local dev fallback (requires GOOGLE_APPLICATION_CREDENTIALS)\n",
    "    client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07afdf5",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get activities\n",
    "query_activities = f\"SELECT * FROM {_GCP_PROJECT_ID}.{_BQ_DATASET_MARTS}.fct_activities\"\n",
    "# query_activities = f\"SELECT * FROM {_GCP_PROJECT_ID}.strava_data.raw_activities\"\n",
    "\n",
    "df_activities = client.query(query_activities).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Count activities: {len(df_activities)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activities.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4212df18",
   "metadata": {},
   "source": [
    "# Filter relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter\n",
    "df_activities_filtered = df_activities[\n",
    "    (df_activities['discipline'] == 'Run')\n",
    "].drop_duplicates(subset=['activity_id'], keep='last').copy()\n",
    "\n",
    "# Canonical types\n",
    "df_activities_filtered[\"start_date_local\"] = pd.to_datetime(df_activities_filtered[\"start_date_local\"], utc=False)\n",
    "\n",
    "# Derived core metric (preferred for modeling)\n",
    "df_activities_filtered[\"pace_sec_per_km\"] = df_activities_filtered[\"moving_time_s\"] / df_activities_filtered[\"distance_km\"]\n",
    "print(f'Len relevant activities: {len(df_activities_filtered)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_activities_filtered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfda72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activities_filtered[df_activities_filtered['is_race'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714f8326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import numpy as np\n",
    "\n",
    "def build_labels_from_runs(\n",
    "    runs_df: pd.DataFrame,\n",
    "    race_flag_col: str = \"is_race\",  # change if your column is named differently\n",
    "    fallback_race_ids: Optional[List[int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    df = runs_df.copy()\n",
    "    \n",
    "    if race_flag_col in df.columns:\n",
    "        labels = df[df[race_flag_col].fillna(False)].copy()\n",
    "    elif fallback_race_ids is not None:\n",
    "        labels = df[df[\"activity_id\"].isin(fallback_race_ids)].copy()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"No race flag column found and no fallback_race_ids provided. \"\n",
    "            \"Either add is_race to your mart table or pass fallback_race_ids.\"\n",
    "        )\n",
    "    \n",
    "    # Label schema\n",
    "    labels = labels.rename(columns={\n",
    "        \"activity_id\": \"race_id\",\n",
    "        \"start_date_local\": \"race_date_local\",\n",
    "        \"distance_km\": \"target_distance_km\",\n",
    "        \"moving_time_s\": \"finish_time_s\",\n",
    "    })[[\"race_id\", \"athlete_id\", \"race_date_local\", \"target_distance_km\", \"finish_time_s\"]]\n",
    "    \n",
    "    \n",
    "    labels = labels.sort_values(\"race_date_local\").reset_index(drop=True)\n",
    "    return labels\n",
    "\n",
    "# ---- If you DON'T have is_race yet, provide fallback list manually:\n",
    "# fallback_race_ids = [1234567890, 2345678901, ...]\n",
    "# labels = build_labels_from_runs(runs, fallback_race_ids=fallback_race_ids)\n",
    "\n",
    "labels = build_labels_from_runs(df_activities_filtered)  # works if runs has is_race\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 3) Feature engineering: leak-proof rolling windows\n",
    "#    One row per race, computed from training before race_date\n",
    "# =========================================\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class WindowSpec:\n",
    "    name: str\n",
    "    days: int\n",
    "\n",
    "WINDOWS = [\n",
    "    WindowSpec(\"7d\", 7),\n",
    "    WindowSpec(\"28d\", 28),\n",
    "    WindowSpec(\"56d\", 56),\n",
    "    WindowSpec(\"84d\", 84),\n",
    "]\n",
    "\n",
    "def approx_quantiles(x: pd.Series, qs=(0.25, 0.5, 0.75)) -> Dict[str, float]:\n",
    "    x = x.dropna()\n",
    "    if len(x) == 0:\n",
    "        return {f\"q{int(q*100)}\": np.nan for q in qs}\n",
    "    vals = x.quantile(list(qs)).to_dict()\n",
    "    return {f\"q{int(q*100)}\": float(vals[q]) for q in qs}\n",
    "\n",
    "def build_features_for_race(runs_df: pd.DataFrame, race_row: pd.Series) -> Dict[str, float]:\n",
    "    athlete_id = race_row[\"athlete_id\"]\n",
    "    race_time = pd.Timestamp(race_row[\"race_date_local\"])\n",
    "    \n",
    "    df = runs_df[runs_df[\"athlete_id\"] == athlete_id].copy()\n",
    "    df = df[df[\"start_date_local\"] < race_time]  # LEAK-PROOF cutoff\n",
    "    \n",
    "    out: Dict[str, float] = {\n",
    "        \"race_id\": int(race_row[\"race_id\"]),\n",
    "        \"athlete_id\": int(athlete_id),\n",
    "        \"race_date_local\": race_time,\n",
    "        \"target_distance_km\": float(race_row[\"target_distance_km\"]),\n",
    "        \"log_target_distance\": float(np.log(float(race_row[\"target_distance_km\"]))),\n",
    "        \"finish_time_s\": int(race_row[\"finish_time_s\"]),\n",
    "    }\n",
    "    \n",
    "    # Recency features (global, not windowed)\n",
    "    if len(df) > 0:\n",
    "        last_run_time = df[\"start_date_local\"].max()\n",
    "        out[\"days_since_last_run\"] = float((race_time.date() - last_run_time.date()).days)\n",
    "    else:\n",
    "        out[\"days_since_last_run\"] = np.nan\n",
    "    \n",
    "    # Define \"long run\" threshold (tune) ============================\n",
    "    LONG_RUN_KM = 18.0\n",
    "    df_long = df[df[\"distance_km\"] >= LONG_RUN_KM]\n",
    "    out[\"days_since_long_run\"] = float((race_time.date() - df_long[\"start_date_local\"].max().date()).days) if len(df_long) else np.nan\n",
    "    \n",
    "    # Rolling windows\n",
    "    for w in WINDOWS:\n",
    "        start = race_time - pd.Timedelta(days=w.days)\n",
    "        d = df[df[\"start_date_local\"] >= start]\n",
    "        \n",
    "        out[f\"runs_{w.name}\"] = float(len(d))\n",
    "        out[f\"dist_km_{w.name}\"] = float(d[\"distance_km\"].sum()) if len(d) else 0.0\n",
    "        out[f\"time_s_{w.name}\"] = float(d[\"moving_time_s\"].sum()) if len(d) else 0.0\n",
    "        out[f\"longest_run_km_{w.name}\"] = float(d[\"distance_km\"].max()) if len(d) else np.nan\n",
    "        \n",
    "        # Time-weighted mean pace: sum(time)/sum(dist)\n",
    "        dist = d[\"distance_km\"].sum()\n",
    "        time = d[\"moving_time_s\"].sum()\n",
    "        out[f\"pace_sec_per_km_{w.name}\"] = float(time / dist) if dist > 0 else np.nan\n",
    "        \n",
    "        # Elevation per km\n",
    "        elev = d[\"elevation_gain_m\"].sum(skipna=True) if \"elevation_gain_m\" in d else np.nan\n",
    "        out[f\"elev_m_per_km_{w.name}\"] = float(elev / dist) if (dist > 0 and pd.notna(elev)) else np.nan\n",
    "        \n",
    "        # HR (time-weighted) where available\n",
    "        if \"has_heartrate\" in d.columns and \"avg_heartrate\" in d.columns:\n",
    "            dh = d[d[\"has_heartrate\"] == True].copy()\n",
    "            denom = dh[\"moving_time_s\"].sum()\n",
    "            out[f\"hr_mean_{w.name}\"] = float((dh[\"avg_heartrate\"] * dh[\"moving_time_s\"]).sum() / denom) if denom > 0 else np.nan\n",
    "            out[f\"hr_coverage_{w.name}\"] = float(len(dh) / len(d)) if len(d) > 0 else np.nan\n",
    "        else:\n",
    "            out[f\"hr_mean_{w.name}\"] = np.nan\n",
    "            out[f\"hr_coverage_{w.name}\"] = np.nan\n",
    "        \n",
    "        # Power (time-weighted) if available\n",
    "        if \"avg_watts\" in d.columns:\n",
    "            dp = d[d[\"avg_watts\"].notna()].copy()\n",
    "            denom = dp[\"moving_time_s\"].sum()\n",
    "            out[f\"watts_mean_{w.name}\"] = float((dp[\"avg_watts\"] * dp[\"moving_time_s\"]).sum() / denom) if denom > 0 else np.nan\n",
    "            out[f\"watts_coverage_{w.name}\"] = float(len(dp) / len(d)) if len(d) > 0 else np.nan\n",
    "        \n",
    "        # Cadence mean\n",
    "        if \"avg_cadence\" in d.columns:\n",
    "            out[f\"cadence_mean_{w.name}\"] = float(d[\"avg_cadence\"].mean()) if len(d) else np.nan\n",
    "        \n",
    "        # Pace distribution (per-run, not time-weighted) for longer windows only\n",
    "        if w.days >= 56:\n",
    "            qs = approx_quantiles(d[\"pace_sec_per_km\"], qs=(0.25, 0.5, 0.75))\n",
    "            out[f\"pace_p25_{w.name}\"] = qs[\"q25\"]\n",
    "            out[f\"pace_p50_{w.name}\"] = qs[\"q50\"]\n",
    "            out[f\"pace_p75_{w.name}\"] = qs[\"q75\"]\n",
    "            out[f\"pace_std_{w.name}\"] = float(d[\"pace_sec_per_km\"].std(ddof=1)) if len(d) >= 2 else np.nan\n",
    "    \n",
    "    # Acute:chronic ratio (7d/28d)\n",
    "    out[\"acr_dist_7d_28d\"] = float(out[\"dist_km_7d\"] / out[\"dist_km_28d\"]) if out[\"dist_km_28d\"] > 0 else np.nan\n",
    "    \n",
    "    return out\n",
    "\n",
    "def build_feature_matrix(runs_df: pd.DataFrame, labels_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, race_row in labels_df.iterrows():\n",
    "        rows.append(build_features_for_race(runs_df, race_row))\n",
    "    Xy = pd.DataFrame(rows).sort_values(\"race_date_local\").reset_index(drop=True)\n",
    "    return Xy\n",
    "\n",
    "Xy = build_feature_matrix(df_activities_filtered, labels)\n",
    "Xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 4) Quick sanity checks (highly recommended)\n",
    "# =========================================\n",
    "# Check leakage cutoff: last training run must be BEFORE race time for each row\n",
    "# (This is ensured by construction, but we can still validate edge cases.)\n",
    "assert Xy[\"days_since_last_run\"].isna().sum() < len(Xy), \"Looks like you have no prior runs before some races.\"\n",
    "\n",
    "# Check targets by distance\n",
    "Xy.groupby(\"target_distance_km\")[\"finish_time_s\"].agg([\"count\", \"mean\", \"min\", \"max\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 5) Train a first baseline model (time-aware split)\n",
    "#    (You can replace later with XGBoost; start simple)\n",
    "# =========================================\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# Define features/target\n",
    "target = \"finish_time_s\"\n",
    "non_features = {\"race_id\", \"athlete_id\", \"race_date_local\", \"finish_time_s\"}\n",
    "feature_cols = [c for c in Xy.columns if c not in non_features]\n",
    "\n",
    "X = Xy[feature_cols]\n",
    "y = Xy[target].astype(float)\n",
    "\n",
    "# Time-based CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "models = {\n",
    "    \"elasticnet\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"model\", ElasticNet(alpha=0.05, l1_ratio=0.3, random_state=42, max_iter=20000)),\n",
    "    ]),\n",
    "    \"hgb\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", HistGradientBoostingRegressor(\n",
    "            max_depth=5,\n",
    "            learning_rate=0.05,\n",
    "            max_iter=500,\n",
    "            random_state=42\n",
    "        )),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "scores = []\n",
    "for name, model in models.items():\n",
    "    fold = 0\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, pred)\n",
    "        scores.append({\"model\": name, \"fold\": fold, \"mae_s\": mae})\n",
    "        \n",
    "pd.DataFrame(scores).groupby(\"model\")[\"mae_s\"].agg([\"mean\",\"std\",\"min\",\"max\"]).sort_values(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d878e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(Xy)\n",
    "print(\"Labeled races:\", n)\n",
    "print(Xy[[\"race_date_local\",\"target_distance_km\",\"finish_time_s\"]].sort_values(\"race_date_local\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 6) Fit final model on all data (for now) + example predictions\n",
    "# =========================================\n",
    "best_model_name = \"hgb\"  # switch based on CV above\n",
    "final_model = models[best_model_name]\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Predict the training set (sanity)\n",
    "Xy_pred = Xy[[\"race_id\",\"race_date_local\",\"target_distance_km\",\"finish_time_s\"]].copy()\n",
    "Xy_pred[\"pred_finish_time_s\"] = final_model.predict(X)\n",
    "\n",
    "# Error summary\n",
    "Xy_pred[\"abs_err_s\"] = (Xy_pred[\"pred_finish_time_s\"] - Xy_pred[\"finish_time_s\"]).abs()\n",
    "Xy_pred.groupby(\"target_distance_km\")[\"abs_err_s\"].agg([\"count\",\"mean\",\"median\",\"max\"]).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 7) Predict \"today\" race times (no future race_id needed)\n",
    "#    Build a \"virtual race\" label row at a given date & distance.\n",
    "# =========================================\n",
    "def predict_for_date_and_distance(\n",
    "    runs_df: pd.DataFrame,\n",
    "    model,\n",
    "    athlete_id: int,\n",
    "    as_of: pd.Timestamp,\n",
    "    distance_km: float\n",
    ") -> float:\n",
    "    fake_label = pd.Series({\n",
    "        \"race_id\": -1,\n",
    "        \"athlete_id\": athlete_id,\n",
    "        \"race_date_local\": as_of,\n",
    "        \"target_distance_km\": distance_km,\n",
    "        \"finish_time_s\": 0,  # placeholder\n",
    "    })\n",
    "    feats = build_features_for_race(runs_df, fake_label)\n",
    "    feats_df = pd.DataFrame([feats])[feature_cols]\n",
    "    pred_s = float(model.predict(feats_df)[0])\n",
    "    return pred_s\n",
    "\n",
    "def format_time(seconds: float) -> str:\n",
    "    seconds = int(round(seconds))\n",
    "    h = seconds // 3600\n",
    "    m = (seconds % 3600) // 60\n",
    "    s = seconds % 60\n",
    "    return f\"{h:d}:{m:02d}:{s:02d}\" if h > 0 else f\"{m:d}:{s:02d}\"\n",
    "\n",
    "athlete_id = int(df_activities_filtered[\"athlete_id\"].mode()[0])  # if single athlete\n",
    "as_of = pd.Timestamp.now()  # local notebook time\n",
    "for d in [5.0, 10.0, 21.0975, 42.195]:\n",
    "    pred = predict_for_date_and_distance(df_activities_filtered, final_model, athlete_id, as_of, d)\n",
    "    print(d, \"km ->\", format_time(pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
